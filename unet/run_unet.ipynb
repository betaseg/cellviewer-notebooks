{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72005c1d",
   "metadata": {},
   "source": [
    "# 3D segmentation of golgi aparatus with 3D U-Net\n",
    "\n",
    "![](../figs/golgi.png)\n",
    "\n",
    "\n",
    "\n",
    "This notebook demonstrates how to train a 3D U-Net model to perform semantic segmentation of the golgi aparatus from 3D FIB-SEM data as described in the paper:\n",
    "\n",
    "*Müller, Andreas, et al. \"3D FIB-SEM reconstruction of microtubule–organelle interaction in whole primary mouse β cells.\" Journal of Cell Biology 220.2 (2021).*\n",
    "\n",
    "\n",
    "\n",
    "1. Install tensorflow with gpu support \n",
    "\n",
    "2. Install csbdeep and dependencies:\n",
    "\n",
    "    - `pip install csbdeep tqdm gputools`\n",
    "    - `pip install git+https://github.com/stardist/augmend.git`\n",
    "    \n",
    "    \n",
    "3. Download the example data (or adapt your own data into the same format)\n",
    "\n",
    "    - `wget https://syncandshare.desy.de/index.php/s/FikPy4k2FHS5L4F/download/data_golgi.zip`\n",
    "    - `unzip data_golgi.zip`\n",
    "\n",
    "   which should result in the following folder structure:\n",
    "    ```\n",
    "    data_golgi\n",
    "    ├── train\n",
    "    │   ├── images\n",
    "    │   └── masks\n",
    "    └── val\n",
    "        ├── images\n",
    "        └── masks\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7b4e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tifffile import imread, imwrite\n",
    "from itertools import chain\n",
    "from skimage.segmentation import find_boundaries\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime\n",
    "from csbdeep.internals.nets import custom_unet\n",
    "from csbdeep.utils import Path, normalize\n",
    "from csbdeep.utils.tf import CARETensorBoard, limit_gpu_memory\n",
    "limit_gpu_memory(fraction=0.8, total_memory=12000)\n",
    "from csbdeep.data.generate import sample_patches_from_multiple_stacks\n",
    "from augmend import Augmend, BaseTransform, Elastic, Identity, FlipRot90, AdditiveNoise, CutOut, GaussianBlur, IntensityScaleShift\n",
    "from model import UNetConfig, UNet\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea98c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path('data_golgi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb420927",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(subset = \"train\", nfiles = None, inds = None, shuffle = True):    \n",
    "    src = root/subset\n",
    "    fx = sorted((src/\"images\").glob(\"*.tif\"))\n",
    "    fy = sorted((src/\"masks\").glob(\"*.tif\"))\n",
    "    assert len(fx) ==len(fy)\n",
    "\n",
    "    for f1, f2 in zip(fx,fy):\n",
    "        print(f\"{Path(f1).name}\")\n",
    "        print(f\"{Path(f2).name}\")\n",
    "    \n",
    "    if shuffle:\n",
    "        np.random.seed(42)\n",
    "        inds0 = np.arange(len(fx))\n",
    "        np.random.shuffle(inds0)\n",
    "        fx = np.array(fx)[inds0]\n",
    "        fy = np.array(fy)[inds0]\n",
    "    \n",
    "    if inds is not None:\n",
    "        fx = np.array(fx)[inds]\n",
    "        fy = np.array(fy)[inds]\n",
    "    else:\n",
    "        fx = fx[:nfiles]\n",
    "        fy = fy[:nfiles]\n",
    "\n",
    "    def crop(x):\n",
    "        return x[tuple(slice(0,(s//8)*8) for s in x.shape)]\n",
    "\n",
    "    X = [crop(imread(str(f))).astype(np.float32)/255. for f in tqdm(fx)]\n",
    "\n",
    "    Y = [crop(imread(str(f)).astype(np.uint8)) for f in tqdm(fy)]\n",
    "\n",
    "    return X,Y\n",
    "\n",
    "def batch_generator(X,Y, patch_size=(32,112,112), batch_size=4, shuffle = True):\n",
    "    if len(X) != len(Y):\n",
    "        raise ValueError(\"len(X) != len(Y)\")\n",
    "\n",
    "    if len(X) < batch_size:\n",
    "        raise ValueError(\"len(X) < batch_size\")\n",
    "\n",
    "    inds = np.arange(len(X))\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.shuffle(inds)\n",
    "\n",
    "    count = 0\n",
    "    while True:\n",
    "        b = tuple(sample_patches_from_multiple_stacks([X[i],Y[i]],\n",
    "                                                      patch_size = patch_size,\n",
    "                                                      n_samples=1) for i in inds[:batch_size])\n",
    "        X_batch , Y_batch = zip(*b)\n",
    "        X_batch = np.stack(X_batch)[:,0]\n",
    "        Y_batch = np.stack(Y_batch)[:,0]\n",
    "\n",
    "        yield X_batch, Y_batch\n",
    "\n",
    "        count += batch_size\n",
    "        if count+batch_size>=len(X) and shuffle:\n",
    "            np.random.shuffle(inds)\n",
    "        inds = np.roll(inds, -batch_size)\n",
    "        count = count % len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f06b6fd",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "\n",
    "The following code trains a 3D U-Net model (using a sum of binary crossentropy and dice loss). You can monitor the progress of the model and its losses with tensorboard:\n",
    "\n",
    "`tensorboard --logdir=models` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f7e7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = get_data(\"train\")\n",
    "Xv, Yv = get_data(\"val\")\n",
    "\n",
    "\n",
    "aug = Augmend()\n",
    "aug.add([FlipRot90(axis = (1,2)),FlipRot90(axis = (1,2))])\n",
    "aug.add([Elastic(grid=5, amount=5, order=0, use_gpu=True, axis = (0,1,2)),\n",
    "             Elastic(grid=5, amount=5, order=0, use_gpu=True, axis = (0,1,2))],\n",
    "            probability=.8)\n",
    "aug.add([AdditiveNoise(sigma=(0,0.05)),Identity()], probability=.5)\n",
    "aug.add([IntensityScaleShift(scale=(.7,1.2), shift=(-0.1,0.1), axis = (0,1,2)),Identity()])\n",
    "\n",
    "\n",
    "def proc_image(x,y, augment = 0):\n",
    "    \"\"\"create border mask etc\"\"\"\n",
    "    if augment>0:\n",
    "        x,y = aug([x,y])\n",
    "    y = (y>0).astype(np.float32)[...,np.newaxis]\n",
    "    x = x[...,np.newaxis]\n",
    "    return x,y\n",
    "\n",
    "def class_generator(gen, augment = 0):\n",
    "    for x,y in gen:\n",
    "        a,b =  tuple(zip(*tuple(proc_image(_x,_y, augment) for _x,_y in zip(x,y))))\n",
    "        yield np.stack(a), np.stack(b)\n",
    "\n",
    "gen = class_generator(batch_generator(X,Y,\n",
    "                                      patch_size=(48,128,128),\n",
    "                                      batch_size=min(1,len(X))),augment = 1)\n",
    "gen_val = class_generator(batch_generator(Xv,Yv,batch_size=min(3,len(Xv)),\n",
    "                                          patch_size=(48,128,128),\n",
    "                                          shuffle = False),augment = 0)\n",
    "\n",
    "conf = UNetConfig(axes = \"ZYX\",\n",
    "                  unet_n_depth = 3,\n",
    "                  unet_pool_size = (2,4,4), \n",
    "                  train_reduce_lr = {'factor': 0.5,\n",
    "                                     'patience': 50,\n",
    "                                    'min_delta': 0},\n",
    "                  train_class_weight = (1,5))\n",
    "\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "model = UNet(conf, name = f\"{timestamp}_unet\",basedir = \"models\")\n",
    "\n",
    "\n",
    "Xvv, Yvv = next(gen_val)\n",
    "\n",
    "model.train(X=None, Y= None,data_gen = gen, validation_data=[Xvv, Yvv],\n",
    "            epochs = 300,\n",
    "            steps_per_epoch = 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e568f3",
   "metadata": {},
   "source": [
    "### Prediction \n",
    "\n",
    "We now will apply the model to a new stack "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aef0eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply(model, x0):\n",
    "    x = x0.astype(np.float32)/255.\n",
    "    n_tiles = tuple(int(np.ceil(s/196)) for s in x0.shape)\n",
    "    y_full = model.predict(x, axes = \"ZYX\", normalizer =None, n_tiles = n_tiles)\n",
    "    \n",
    "    y = y_full>=0.5\n",
    "    \n",
    "    return y\n",
    "\n",
    "\n",
    "fname_input = \"...\"\n",
    "outdir = 'output'\n",
    "\n",
    "# load file \n",
    "x0 = imread(fname)\n",
    "\n",
    "model = UNet(None, \"unet\", basedir = \"models\")\n",
    "\n",
    "y = apply(model, x0)\n",
    "\n",
    "\n",
    "# save output \n",
    "out = Path(outdir)\n",
    "\n",
    "out.mkdir(exist_ok=True, parents=True)\n",
    "imwrite(out/f\"{Path(fname_input).stem}.unet.tif\",y.astype(np.uint16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867300fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "00168f89ccf4c7fcc260edb50749800ac69cf2b3b76b0d2e1d6890c83d8c9819"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
